<h3>Starting kit</h3>
<p>The AutoDL starting kit is everything you need to</p>
<ol>
<li>make a test submission with the contained baseline method;</li>
<li>create your own&nbsp;<strong>sample code submission</strong>&nbsp;(by modifying the file model.py, see more details in README.md)</li>
<li>run local test.</li>
</ol>
<p>You can download it following this link:</p>
<h3 style="text-align: center;"><span style="text-decoration: underline;"><a href="https://github.com/zhengying-liu/autodl_starting_kit_stable" target="_blank">Download the Starting Kit</a></span></h3>
<h3>Larger practice datasets</h3>
<table border="1" cellspacing="1" cellpadding="1" align="left">
<tbody>
<tr>
<td style="text-align: left;">&nbsp;#&nbsp;</td>
<td style="text-align: left;">&nbsp;Name</td>
<td style="text-align: left;">&nbsp;Domain</td>
<td style="text-align: left;">&nbsp;Size</td>
<td style="text-align: left;">&nbsp;Source</td>
<td style="text-align: left;">
<p>&nbsp;Data (w/o test labels)</p>
</td>
<td style="text-align: left;">&nbsp;Test labels</td>
</tr>
<tr>
<td>&nbsp;1</td>
<td>&nbsp;ADULT</td>
<td>&nbsp;tabular</td>
<td>&nbsp;1.9 MB</td>
<td>&nbsp;<a href="https://archive.ics.uci.edu/ml/datasets/adult" target="_blank">Adult</a></td>
<td>&nbsp;<a href="../../my/datasets/download/c92700af-3b0f-432a-b784-898383fda1b2">adult.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/4f48064f-3da6-48a5-9ed6-9a2b260c47c4">adult.solution</a></td>
</tr>
<tr>
<td>&nbsp;2</td>
<td>&nbsp;KATZE</td>
<td>&nbsp;video</td>
<td>&nbsp;1.94 GB</td>
<td style="text-align: left;">&nbsp;<a href="http://www.nada.kth.se/cvap/actions/" target="_blank">KTH Human Actions</a></td>
<td>&nbsp;<a href="../../my/datasets/download/49288e21-67eb-4984-b8fe-dc23e53e37b3">katze.data</a>&nbsp;</td>
<td>&nbsp;<a href="../../my/datasets/download/0cf44915-ac2f-4e5f-9b12-432c1ddac1d3">katze.solution</a>&nbsp;</td>
</tr>
<tr>
<td>&nbsp;3</td>
<td>&nbsp;STARCRAFT</td>
<td>&nbsp;speech</td>
<td>&nbsp;732 MB</td>
<td style="text-align: left;">&nbsp;<a href="https://www.kaggle.com/c/tensorflow-speech-recognition-challenge/data" target="_blank">TensorFlow Speech Commands</a></td>
<td>&nbsp;<a href="../../my/datasets/download/910e4256-b8bc-48fd-aa19-3475165eb5d2">starcraft.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/b5632ab4-624e-4ccc-8873-1fd5825b1e24">starcraft.solution</a></td>
</tr>
<tr>
<td>&nbsp;4</td>
<td>&nbsp;TWEET</td>
<td>&nbsp;text</td>
<td>&nbsp;604 MB</td>
<td style="text-align: left;">&nbsp;<a href="http://qwone.com/~jason/20Newsgroups/" target="_blank">20 Newsgroups</a></td>
<td>&nbsp;<a href="../../my/datasets/download/fea6c7bb-b398-4757-924c-b20f16bf4fde">tweet.data</a>&nbsp;</td>
<td>&nbsp;<a href="../../my/datasets/download/724b6bef-f223-4828-881c-2b44b286dd24">tweet.solution</a></td>
</tr>
<tr>
<td style="text-align: left;">&nbsp;5</td>
<td style="text-align: left;">&nbsp;MUNSTER</td>
<td style="text-align: left;">&nbsp;image</td>
<td style="text-align: left;">&nbsp;17.2 MB</td>
<td style="text-align: left;">&nbsp;<a href="http://yann.lecun.com/exdb/mnist/" target="_blank">MNIST</a></td>
<td style="text-align: left;">&nbsp;<a href="../../my/datasets/download/9ecba9a7-a066-4888-9c00-e0235617446d">munster.data</a>&nbsp;</td>
<td style="text-align: left;">&nbsp;<a href="../../my/datasets/download/feb8a3b3-22ed-4dfc-8935-664ca7e15f2f">munster.solution</a></td>
</tr>
</tbody>
</table>
<h3>&nbsp;</h3>
<h3>&nbsp;</h3>
<h3>&nbsp;</h3>
<div>
<p>&nbsp;</p>
<p><strong>Usage</strong>: Dowload and put only ONE pair of data and solution (e.g. adult.data and adult.solution) in the directory AutoDL_sample_data/ (after unzipping). You can also put them in a directory of your choice and specify the path when calling `run_local_test.py`.</p>
<h3>Some statistics/info on these datasets&nbsp;</h3>
<table border="1" cellspacing="1" cellpadding="1" align="left">
<tbody>
<tr>
<td style="text-align: left;">&nbsp;#&nbsp;</td>
<td style="text-align: left;">&nbsp;Name</td>
<td style="text-align: left;">
<p>&nbsp;num_train</p>
</td>
<td style="text-align: left;">
<p>&nbsp;num_test</p>
</td>
<td style="text-align: left;">
<p>&nbsp;col_count</p>
</td>
<td style="text-align: left;">
<p>&nbsp;row_count</p>
</td>
<td style="text-align: left;">
<p>&nbsp;sequence_size</p>
</td>
<td style="text-align: left;">
<p>&nbsp;output_dim</p>
</td>
<td style="text-align: left;">
<p>&nbsp;has_locality_col</p>
</td>
<td>
<p style="text-align: left;">&nbsp;has_locality_row</p>
</td>
</tr>
<tr>
<td>&nbsp;1</td>
<td>&nbsp;ADULT</td>
<td>&nbsp;39074</td>
<td>&nbsp;9768</td>
<td>&nbsp;24</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;3</td>
<td>&nbsp;false</td>
<td>&nbsp;false</td>
</tr>
<tr>
<td>&nbsp;2</td>
<td>&nbsp;KATZE</td>
<td>&nbsp;1528</td>
<td>&nbsp;863</td>
<td>&nbsp;160</td>
<td>&nbsp;120</td>
<td>&nbsp;181</td>
<td>&nbsp;6</td>
<td>&nbsp;true</td>
<td>&nbsp;true</td>
</tr>
<tr>
<td>&nbsp;3</td>
<td>&nbsp;TYPHOON</td>
<td>&nbsp;177080</td>
<td>&nbsp;64145</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;1934</td>
<td>&nbsp;71</td>
<td>&nbsp;false</td>
<td>&nbsp;false</td>
</tr>
<tr>
<td>&nbsp;4</td>
<td>&nbsp;TWEET</td>
<td>&nbsp;11314</td>
<td>&nbsp;7532</td>
<td>&nbsp;50</td>
<td>&nbsp;1</td>
<td>&nbsp;473</td>
<td>&nbsp;20</td>
<td>&nbsp;false</td>
<td>&nbsp;false</td>
</tr>
<tr>
<td>&nbsp;5</td>
<td>&nbsp;MUNSTER</td>
<td>&nbsp;60000</td>
<td>&nbsp;10000</td>
<td>&nbsp;28</td>
<td>&nbsp;28</td>
<td>&nbsp;1</td>
<td>&nbsp;10</td>
<td>&nbsp;true</td>
<td>&nbsp;true</td>
</tr>
</tbody>
</table>
<h3>&nbsp;</h3>
<h3>&nbsp;</h3>
<h3>&nbsp;</h3>
<div>
<p>&nbsp;</p>
</div>
<p>The columns correspond to:</p>
<p>num_train/num_test: number of training/test examples</p>
<p>col_count/row_count/sequence_size: shape parameters of the examples (in AutoDL challenge, every example is represented by a 3D tensor with axes x, y and t (t for time))</p>
<p>output_dim: number of classes</p>
<p>has_locality_col/has_locality_row:&nbsp;indicate if column/row indices carry some structure/information based on closeness of indices, like in an image or in a video.</p>
</div>
<h3>Data format</h3>
<p>Data are not pre-processed in a uniform feature vector representation; they include all data types representable as spatio-temporal sequences. We use a generic data format based on&nbsp;<a href="https://www.tensorflow.org/programmers_guide/datasets#consuming_tfrecord_data">TFRecords</a>, used by <a href="https://www.tensorflow.org/">TensorFlow</a>. This format allows us to format any 2D+time data, including text, speech, image, video, etc. This will not however impose to participants to use deep learning algorithms nor even Tensorflow. If you want to practice designing algorithms with your own datasets, we provide <a href="https://github.com/zhengying-liu/autodl-contrib/tree/master/tfrecord_format">instructions to help you</a>.</p>
