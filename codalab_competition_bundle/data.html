<h2>Datasets</h2>
<p>Each dataset in this competition comes from one of following 5 domains: image, video, speech, text or tabular. Every dataset is formatted in <a href="https://www.tensorflow.org/tutorials/load_data/tfrecord">TFRecords</a>&nbsp;and split into a train set (with true labels) and a test set (without true labels). The data loading process is done in the <a href="https://github.com/zhengying-liu/autodl_starting_kit_stable/tree/master/AutoDL_ingestion_program">ingestion program</a> (thus common to all participants), which parses these TFRecords to a `tf.data.Dataset` object. Each of its examples is of the form</p>
<pre>(example, labels)</pre>
<p>where `example` is a dense <strong>4-D Tensor</strong> of dtype <a href="https://github.com/zhengying-liu/autodl_starting_kit_stable/blob/e277cbb3a4d156f90fefe6c707c1bddc805d8ad5/data_browser.py#L122">tf.float32</a> and of shape</p>
<pre>(sequence_size, row_count, col_count, num_channels)</pre>
<p>and `labels` is a 1-D Tensor of shape</p>
<pre>(output_dim,).</pre>
<p>Here `output_dim` represents number of classes of the&nbsp;multilabel classification task.</p>
<h2>Metadata</h2>
<p>The metadata of each dataset contains info such as the shape of examples, number of examples, number of classes, etc. These info can be accessed by calling different functions found at <a href="https://github.com/zhengying-liu/autodl_starting_kit_stable/blob/e277cbb3a4d156f90fefe6c707c1bddc805d8ad5/AutoDL_ingestion_program/dataset.py#L41">here</a>.</p>
<p>Although the domain information is not given directly in the metadata, it can be inferred from metadata by a function similar to <a href="https://github.com/zhengying-liu/autodl_starting_kit_stable/blob/e277cbb3a4d156f90fefe6c707c1bddc805d8ad5/data_browser.py#L122">this one</a>.</p>
<h2>Specification for text datasets</h2>
<p>Although it is straight-forward to interpret the 4-D Tensor representation of each example for most domains, we need to make some manual choices to encode <strong>text</strong> datasets. The choices we made are:&nbsp;</p>
<ul>
<li>For English, split the original document by space to tokenize; For Chinese, consider each character as a token;</li>
<li>Construct a vocabulary and map each of these tokens to an integer index;</li>
<li>Replace each token by the index (cast as tf.float32);</li>
<li>Each example (document) is then a sequence of integers.</li>
</ul>
<p>The mapping from token to integer index can be accessed by calling</p>
<pre>token_to_index = metadata.get_channel_to_index_map()</pre>
<p><strong>Embedding weights:</strong></p>
<p>In the Docker image running by the platform (<strong>evariste/autodl:gpu-latest</strong>),&nbsp; a&nbsp;<strong>built-in embedding model</strong>&nbsp;is provided for Chinese and English respectively, and the path of the embedding models is "<strong>/app/embedding".</strong>&nbsp;Both the embedding models are from&nbsp;<a href="https://fasttext.cc/">fastText</a>&nbsp;(<a href="https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.zh.300.vec.gz">Chinese</a>,&nbsp;<a href="https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.en.300.vec.gz">English</a>)</p>
<h2>Public datasets</h2>
<p style="text-align: left;">We provide a list of public datasets. You will have access to the data (training set and test set) AND the true labels for these datasets. Notice that the video datasets do not include a sound track.</p>
<table border="1" cellspacing="1" cellpadding="1">
<tbody>
<tr>
<td>&nbsp;#&nbsp;</td>
<td>&nbsp;Name</td>
<td>&nbsp;Type</td>
<td>&nbsp;Domain</td>
<td>&nbsp;Size</td>
<td>&nbsp;Source</td>
<td>
<p>&nbsp;Data (w/o test labels)</p>
</td>
<td>&nbsp;Test labels</td>
</tr>
<tr>
<td>&nbsp;1</td>
<td>&nbsp;Munster</td>
<td>&nbsp;Image</td>
<td>&nbsp;HWR</td>
<td>&nbsp;18 MB</td>
<td>&nbsp;<a href="http://yann.lecun.com/exdb/mnist/" target="_blank">MNIST</a></td>
<td>&nbsp;<a href="../../my/datasets/download/6662aa6e-75ab-439c-bf98-97dd11401053">munster.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/f3a61a40-b1f1-4ded-bc55-fb730a12f4c4">munster.solution</a></td>
</tr>
<tr>
<td>&nbsp;2</td>
<td>&nbsp;City</td>
<td>&nbsp;Image</td>
<td>&nbsp;Objects</td>
<td>&nbsp;128 MB</td>
<td>&nbsp;<a href="https://www.cs.toronto.edu/~kriz/cifar.html">Cifar-10</a></td>
<td>&nbsp;<a href="../../my/datasets/download/cf0f810e-4818-4c8a-bf48-cbf9b6599928">city.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/c64e3ebb-664f-45f1-8666-1054d262a85c">city.solution</a></td>
</tr>
<tr>
<td>&nbsp;3</td>
<td>&nbsp;Chucky</td>
<td>&nbsp;Image</td>
<td>&nbsp;Objects</td>
<td>&nbsp;128 MB</td>
<td>&nbsp;<a href="https://www.cs.toronto.edu/~kriz/cifar.html">Cifar-100</a></td>
<td>&nbsp;<a href="../../my/datasets/download/d06aa5fc-1fb5-4283-8e05-abed4ccdd975">chucky.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/29932707-21cc-4670-a7db-cdc246a8ab71">chucky.solution</a></td>
</tr>
<tr>
<td>&nbsp;4</td>
<td>&nbsp;Pedro</td>
<td>&nbsp;Image</td>
<td>&nbsp;People</td>
<td>&nbsp;377 MB</td>
<td>&nbsp;<a href="https://github.com/xh-liu/HydraPlus-Net"><span style="font-size: 10pt; font-family: Arial; font-style: normal;" data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;PA-100K&quot;}" data-sheets-userformat="{&quot;2&quot;:513,&quot;3&quot;:{&quot;1&quot;:0},&quot;12&quot;:0}">PA-100K</span></a></td>
<td>&nbsp;<a href="../../my/datasets/download/61a074cd-e909-4d49-b313-7da0d4f7dc8b">pedro.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/852c1e68-5e91-477e-bef0-824b503814e8">pedro.solution</a></td>
</tr>
<tr>
<td>&nbsp;5</td>
<td>&nbsp;Decal</td>
<td>&nbsp;Image</td>
<td>&nbsp;Aerial</td>
<td>&nbsp;73 MB</td>
<td>&nbsp;<a href="http://www.escience.cn/people/gongcheng/NWPU-VHR-10.html">NWPU VHR-10</a></td>
<td>&nbsp;<a href="../../my/datasets/download/dfd93c39-e0d4-41b2-b332-4dd002676e05">decal.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/d72cba79-3051-4779-b624-e50335aad874">decal.solution</a></td>
</tr>
<tr>
<td>&nbsp;6</td>
<td>&nbsp;Hammer</td>
<td>&nbsp;Image</td>
<td>&nbsp;Medical</td>
<td>&nbsp;111 MB</td>
<td>&nbsp;<a href="https://www.nature.com/articles/sdata2018161">Ham10000</a></td>
<td>&nbsp;<a href="../../my/datasets/download/eb569948-72f0-4002-8e4d-479a27766cbf">hammer.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/c3729c98-4755-47a2-b764-a4159c5ca152">hammer.solution</a></td>
</tr>
<tr>
<td>&nbsp;7</td>
<td>&nbsp;Kreatur</td>
<td>&nbsp;Video</td>
<td>&nbsp;Action</td>
<td>&nbsp;469 MB</td>
<td>&nbsp;<a href="https://www.nature.com/articles/sdata2018161">KTH</a></td>
<td>&nbsp;<a href="../../my/datasets/download/c240df57-b144-41df-a059-05bc859d2621">kreatur.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/31ecdb19-c25a-420f-9764-8d1783705deb">kreatur.solution</a></td>
</tr>
<tr>
<td>&nbsp;8</td>
<td>&nbsp;Kreatur3</td>
<td>&nbsp;Video</td>
<td>&nbsp;Action</td>
<td>&nbsp;588 MB</td>
<td>&nbsp;<a href="https://www.nature.com/articles/sdata2018161">KTH</a></td>
<td>&nbsp;<a href="../../my/datasets/download/08c2afcd-74b1-4c5e-8b93-9f6c9a96add2">kreatur3.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/10e04890-f05a-4004-a499-1cc167769edd">kreatur3.solution</a></td>
</tr>
<tr>
<td>&nbsp;9</td>
<td>&nbsp;Kraut</td>
<td>&nbsp;Video</td>
<td>&nbsp;Action</td>
<td>&nbsp;1.9 GB</td>
<td>&nbsp;<a href="https://www.nature.com/articles/sdata2018161">KTH</a></td>
<td>&nbsp;<a href="../../my/datasets/download/a1d9f706-cf8d-4a63-a544-552d6b85d6c4">kraut.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/47ff016d-cc66-47a9-945d-bc01fd9096c9">kraut.solution</a></td>
</tr>
<tr>
<td>&nbsp;10</td>
<td>&nbsp;Katze</td>
<td>&nbsp;Video</td>
<td>&nbsp;Action</td>
<td>&nbsp;1.9 GB</td>
<td>&nbsp;<a href="https://www.nature.com/articles/sdata2018161">KTH</a></td>
<td>&nbsp;<a href="../../my/datasets/download/611a42fa-da42-4a30-8c7a-69230d9eeb92">katze.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/a04de92e-b04b-49a6-96c2-5910c64f9b3c">katze.solution</a></td>
</tr>
<tr>
<td>&nbsp;11</td>
<td>&nbsp;data01</td>
<td>&nbsp;Speech</td>
<td>&nbsp;Speaker</td>
<td>&nbsp;1.8 GB</td>
<td>&nbsp;--</td>
<td>&nbsp;<a href="../../my/datasets/download/c15f1b70-4f07-4e9e-9817-d785b1674966">data01.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/358a227e-986d-48ad-a994-70b12a9bfcc3">data01.solution</a></td>
</tr>
<tr>
<td>&nbsp;12</td>
<td>&nbsp;data02</td>
<td>&nbsp;Speech</td>
<td>&nbsp;Emotion</td>
<td>&nbsp;53 MB</td>
<td>&nbsp;--</td>
<td>&nbsp;<a href="../../my/datasets/download/3961f962-88db-47ee-a756-2152753ba900">data02.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/9be871dc-1356-4600-962e-9a43154a1e38">data02.solution</a></td>
</tr>
<tr>
<td>&nbsp;13</td>
<td>&nbsp;data03</td>
<td>&nbsp;Speech</td>
<td>&nbsp;Accent</td>
<td>&nbsp;1.8 GB</td>
<td>&nbsp;--</td>
<td>&nbsp;<a href="../../my/datasets/download/a97ddb39-1470-4a80-81b0-1c26dfa29335">data03.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/a6baf245-03a6-42b5-b870-df57e3a27723">data03.solution</a></td>
</tr>
<tr>
<td>&nbsp;14</td>
<td>&nbsp;data04</td>
<td>&nbsp;Speech</td>
<td>&nbsp;Genre</td>
<td>&nbsp;469 MB</td>
<td>&nbsp;--</td>
<td>&nbsp;<a href="../../my/datasets/download/c8d15be0-e1fa-4899-940e-0d7e1794a835">data04.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/32fd9ca3-865c-4135-a70c-1543160cf6ab">data04.solution</a></td>
</tr>
<tr>
<td>&nbsp;15</td>
<td>&nbsp;data05</td>
<td>&nbsp;Speech</td>
<td>&nbsp;Language</td>
<td>&nbsp;208 MB</td>
<td>&nbsp;--</td>
<td>&nbsp;<a href="../../my/datasets/download/cccc9147-7d1f-4119-888b-1b87f142b721">data05.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/4f802113-a899-40a8-b293-e119dd7c54f5">data05.solution</a></td>
</tr>
<tr>
<td>&nbsp;16</td>
<td>&nbsp;O1</td>
<td>&nbsp;Text</td>
<td>&nbsp;Comments</td>
<td>&nbsp;828 KB</td>
<td>&nbsp;--</td>
<td>&nbsp;<a href="../../my/datasets/download/4b98c65f-1922-4ff4-8e2a-ab7a022ef1da">O1.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/888e1c1c-a39c-40b9-b6f7-cc2eff7a299d">O1.solution</a></td>
</tr>
<tr>
<td>&nbsp;17</td>
<td>&nbsp;O2</td>
<td>&nbsp;Text</td>
<td>&nbsp;Emotion</td>
<td>&nbsp;25 MB</td>
<td>&nbsp;--</td>
<td>&nbsp;<a href="../../my/datasets/download/f831b0d6-0a53-4c93-b9cf-8cf1f2128d24">O2.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/b6513cb2-e4f2-46a8-a7cf-1d8441a00a56">O2.solution</a></td>
</tr>
<tr>
<td>&nbsp;18</td>
<td>&nbsp;O3</td>
<td>&nbsp;Text</td>
<td>&nbsp;News</td>
<td>&nbsp;88 MB</td>
<td>&nbsp;--</td>
<td>&nbsp;<a href="../../my/datasets/download/4545d366-12f4-442c-87e4-f908fcd79698">O3.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/4bb6ebd3-f991-4a6b-8cd1-864a0f3a1abd">O3.solution</a></td>
</tr>
<tr>
<td>&nbsp;19</td>
<td>&nbsp;O4</td>
<td>&nbsp;Text</td>
<td>&nbsp;Spam</td>
<td>&nbsp;87 MB</td>
<td>&nbsp;--</td>
<td>&nbsp;<a href="../../my/datasets/download/2bdf5e4e-8d02-4c85-98b2-0b28a6176db9">O4.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/e09837eb-8144-4850-ad38-c1ba81426c0b">O4.solution</a></td>
</tr>
<tr>
<td>&nbsp;20</td>
<td>&nbsp;O5</td>
<td>&nbsp;Text</td>
<td>&nbsp;News</td>
<td>&nbsp;14 MB</td>
<td>&nbsp;--</td>
<td>&nbsp;<a href="../../my/datasets/download/09ec4daf-fba2-41e1-80d0-429772d59d58">O5.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/18c8e3eb-2341-41ed-9a44-8d2c94042c30">O5.solution</a></td>
</tr>
<tr>
<td>&nbsp;21</td>
<td>&nbsp;Adult</td>
<td>&nbsp;Tabular</td>
<td>&nbsp;Census</td>
<td>&nbsp;2 MB</td>
<td>&nbsp;<a href="https://archive.ics.uci.edu/ml/datasets/adult" target="_blank">Adult</a></td>
<td>&nbsp;<a href="../../my/datasets/download/4ad27a85-4932-409b-a33d-a3b1c4ec1893">adult.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/c125d32c-3e89-456a-a82d-760fc4b60e4c">adult.solution</a></td>
</tr>
<tr>
<td>&nbsp;22</td>
<td>&nbsp;Dilbert</td>
<td>&nbsp;Tabular</td>
<td>&nbsp;--</td>
<td>&nbsp;162 MB</td>
<td>&nbsp;--</td>
<td>&nbsp;<a href="../../my/datasets/download/71f517b0-85c2-4a7d-8df3-d2a5998a9d78">dilbert.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/7734cc00-1583-44c8-80f5-156a11b12952">dilbert.solution</a></td>
</tr>
<tr>
<td>&nbsp;23</td>
<td>&nbsp;Digits</td>
<td>&nbsp;Tabular</td>
<td>&nbsp;HWR</td>
<td>&nbsp;137 MB</td>
<td>&nbsp;<a href="http://yann.lecun.com/exdb/mnist/" target="_blank">MNIST</a></td>
<td>&nbsp;<a href="../../my/datasets/download/03e69995-2b8b-4f60-b43b-4458aa51e9c0">digits.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/e29c6cb2-8748-4e26-9c91-66a2b0dd41c2">digits.solution</a></td>
</tr>
<tr>
<td>&nbsp;24</td>
<td>&nbsp;Madeline</td>
<td>&nbsp;Tabular</td>
<td>&nbsp;--</td>
<td>&nbsp;2.6 MB</td>
<td>&nbsp;--</td>
<td>&nbsp;<a href="../../my/datasets/download/1d7910ca-ee43-41fc-aca9-0dfcd800d93b">madeline.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/a86e0e7f-9b07-44f1-92ba-0a5f72cddb6b">madeline.solution</a></td>
</tr>
</tbody>
</table>
<p>&nbsp;</p>
<table border="1" cellspacing="1" cellpadding="1">
<tbody>
<tr>
<td>
<p>&nbsp;#&nbsp;</p>
</td>
<td>&nbsp;Name</td>
<td>
<p>&nbsp;num_train</p>
</td>
<td>
<p>&nbsp;num_test</p>
</td>
<td>
<p>&nbsp;sequence_size</p>
</td>
<td>
<p>&nbsp;row_count</p>
</td>
<td>
<p>&nbsp;col_count</p>
</td>
<td>
<p>&nbsp;num_channels</p>
</td>
<td>&nbsp;output_dim&nbsp;</td>
</tr>
<tr>
<td>&nbsp;1</td>
<td>&nbsp;Munster</td>
<td>&nbsp;60000</td>
<td>&nbsp;10000</td>
<td>&nbsp;1</td>
<td>&nbsp;28</td>
<td>&nbsp;28</td>
<td>&nbsp;1</td>
<td>&nbsp;10</td>
</tr>
<tr>
<td>&nbsp;2</td>
<td>&nbsp;City</td>
<td>&nbsp;48060</td>
<td>&nbsp;11940</td>
<td>&nbsp;1</td>
<td>&nbsp;32</td>
<td>&nbsp;32</td>
<td>&nbsp;3</td>
<td>&nbsp;10</td>
</tr>
<tr>
<td>&nbsp;3</td>
<td>&nbsp;Chucky</td>
<td>&nbsp;48061</td>
<td>&nbsp;11939</td>
<td>&nbsp;1</td>
<td>&nbsp;32</td>
<td>&nbsp;32</td>
<td>&nbsp;3</td>
<td>&nbsp;100</td>
</tr>
<tr>
<td>&nbsp;4</td>
<td>&nbsp;Pedro</td>
<td>&nbsp;80095</td>
<td>&nbsp;19905</td>
<td>&nbsp;1</td>
<td>&nbsp;-1</td>
<td>&nbsp;-1</td>
<td>&nbsp;3</td>
<td>&nbsp;26</td>
</tr>
<tr>
<td>&nbsp;5</td>
<td>&nbsp;Decal</td>
<td>&nbsp;634</td>
<td>&nbsp;166</td>
<td>&nbsp;1</td>
<td>&nbsp;-1</td>
<td>&nbsp;-1</td>
<td>&nbsp;3</td>
<td>&nbsp;11</td>
</tr>
<tr>
<td>&nbsp;6</td>
<td>&nbsp;Hammer</td>
<td>&nbsp;8050</td>
<td>&nbsp;1965</td>
<td>&nbsp;1</td>
<td>&nbsp;400</td>
<td>&nbsp;300</td>
<td>&nbsp;3</td>
<td>&nbsp;7</td>
</tr>
<tr>
<td>&nbsp;7</td>
<td>&nbsp;Kreatur</td>
<td>&nbsp;1528</td>
<td>&nbsp;863</td>
<td>&nbsp;181</td>
<td>&nbsp;60</td>
<td>&nbsp;80</td>
<td>&nbsp;1</td>
<td>&nbsp;4</td>
</tr>
<tr>
<td>&nbsp;8</td>
<td>&nbsp;Kreatur3</td>
<td>&nbsp;1528</td>
<td>&nbsp;863</td>
<td>&nbsp;181</td>
<td>&nbsp;60</td>
<td>&nbsp;80</td>
<td>&nbsp;3</td>
<td>&nbsp;4</td>
</tr>
<tr>
<td>&nbsp;9</td>
<td>&nbsp;Kraut</td>
<td>&nbsp;1528</td>
<td>&nbsp;863</td>
<td>&nbsp;181</td>
<td>&nbsp;120</td>
<td>&nbsp;160</td>
<td>&nbsp;1</td>
<td>&nbsp;4</td>
</tr>
<tr>
<td>&nbsp;10</td>
<td>&nbsp;Katze</td>
<td>&nbsp;1528</td>
<td>&nbsp;863</td>
<td>&nbsp;181</td>
<td>&nbsp;120</td>
<td>&nbsp;160</td>
<td>&nbsp;1</td>
<td>&nbsp;6</td>
</tr>
<tr>
<td>&nbsp;11</td>
<td>&nbsp;data01</td>
<td>&nbsp;3000</td>
<td>&nbsp;3000</td>
<td>&nbsp;-1</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;100</td>
</tr>
<tr>
<td>&nbsp;12</td>
<td>&nbsp;data02</td>
<td>&nbsp;428</td>
<td>&nbsp;107</td>
<td>&nbsp;-1</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;7</td>
</tr>
<tr>
<td>&nbsp;13</td>
<td>&nbsp;data03</td>
<td>&nbsp;796</td>
<td>&nbsp;200</td>
<td>&nbsp;-1</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;3</td>
</tr>
<tr>
<td>&nbsp;14</td>
<td>&nbsp;data04</td>
<td>&nbsp;940</td>
<td>&nbsp;473</td>
<td>&nbsp;-1</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;20</td>
</tr>
<tr>
<td>&nbsp;15</td>
<td>&nbsp;data05</td>
<td>&nbsp;199</td>
<td>&nbsp;597</td>
<td>&nbsp;-1</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;10</td>
</tr>
<tr>
<td>&nbsp;16</td>
<td>&nbsp;O1</td>
<td>&nbsp;7796</td>
<td>&nbsp;1817</td>
<td>&nbsp;-1</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;2</td>
</tr>
<tr>
<td>&nbsp;17</td>
<td>&nbsp;O2</td>
<td>&nbsp;11308</td>
<td>&nbsp;7538</td>
<td>&nbsp;-1</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;20</td>
</tr>
<tr>
<td>&nbsp;18</td>
<td>&nbsp;O3</td>
<td>&nbsp;60000</td>
<td>&nbsp;40000</td>
<td>&nbsp;-1</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;2</td>
</tr>
<tr>
<td>&nbsp;19</td>
<td>&nbsp;O4</td>
<td>&nbsp;54990</td>
<td>&nbsp;10010</td>
<td>&nbsp;-1</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;10</td>
</tr>
<tr>
<td>&nbsp;20</td>
<td>&nbsp;O5</td>
<td>&nbsp;155952</td>
<td>&nbsp;72048</td>
<td>&nbsp;-1</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;18</td>
</tr>
<tr>
<td>&nbsp;21</td>
<td>&nbsp;Adult</td>
<td>&nbsp;39073</td>
<td>&nbsp;9768</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;24</td>
<td>&nbsp;1</td>
<td>&nbsp;3</td>
</tr>
<tr>
<td>&nbsp;22</td>
<td>&nbsp;Dilbert</td>
<td>&nbsp;14871</td>
<td>&nbsp;9709</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;2000</td>
<td>&nbsp;1</td>
<td>&nbsp;5</td>
</tr>
<tr>
<td>&nbsp;23</td>
<td>&nbsp;Digits</td>
<td>&nbsp;35000</td>
<td>&nbsp;35000</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;1568</td>
<td>&nbsp;1</td>
<td>&nbsp;10</td>
</tr>
<tr>
<td>&nbsp;24</td>
<td>&nbsp;Madeline</td>
<td>&nbsp;4222</td>
<td>&nbsp;3238</td>
<td>&nbsp;1</td>
<td>&nbsp;1</td>
<td>&nbsp;259</td>
<td>&nbsp;1</td>
<td>&nbsp;2</td>
</tr>
</tbody>
</table>
<p>&nbsp;</p>
<ul>
<li>num_train/num_test: number of training/test examples</li>
<li>sequence_size/row_count/col_count/num_channels: shape of the examples. -1 means the value varies from one example to another.</li>
<li>output_dim: number of classes</li>
</ul>
<p>These data were re-formatted from original public datasets. If you use them, please make sure to acknowledge the original data donnors (see "Source" in the data table) and check the tems of use.</p>
<p><strong>To download all public datasets at once:</strong></p>
<pre>cd autodl_starting_kit_stable<br />python download_public_datasets.py</pre>
<h2>Format and use your own datasets</h2>
<p>We provide toolkit to participants to format their own datasets to the same format of this challenge. If you want to practice designing algorithms with your own datasets, <a href="https://github.com/zhengying-liu/autodl-contrib/blob/master/README.md">follow these steps</a>.&nbsp;</p>