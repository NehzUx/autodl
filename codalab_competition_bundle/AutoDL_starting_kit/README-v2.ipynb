{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div><img src=\"logo.png\" width=\"220\" ALIGN=\"left\" border=\"20\"></div>\n",
    "<h1>AutoDL Starting Kit </h1>\n",
    "\n",
    "\n",
    "<br>This code was tested with <br>\n",
    "Python 3.6.6 |Anaconda custom (64-bit)| (default, Jun 28 2018, 11:07:29) (https://anaconda.org/)<br>\n",
    "<br>\n",
    "</center>\n",
    "<p>\n",
    "\n",
    "ALL INFORMATION, SOFTWARE, DOCUMENTATION, AND DATA ARE PROVIDED \"AS-IS\".\n",
    "UNIVERSITE PARIS SUD, INRIA, CHALEARN, AND/OR OTHER ORGANIZERS\n",
    "OR CODE AUTHORS DISCLAIM ANY EXPRESSED OR IMPLIED WARRANTIES.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Download This Starting Kit\n",
    "\n",
    " You can download this starting kit by clicking on the green button \"Clone or download\" on top of [this GitHub repo](https://github.com/zhengying-liu/autodl_starting_kit_stable), then \"Download ZIP\". You'll have this whole starting kit by unzipping the downloaded file.\n",
    "\n",
    " Another convenient way is to use **git clone**:\n",
    " ```\n",
    " cd <path_to_your_directory>\n",
    " git clone https://github.com/zhengying-liu/autodl_starting_kit_stable.git\n",
    " ```\n",
    "\n",
    " Then you can begin your participation to AutoDL challenge by carefully reading this README.md file (which you are already doing).\n",
    "\n",
    "## Local Development and Testing\n",
    "To make your own submission to AutoDL challenge, you need to modify the file\n",
    "`model.py` in `AutoDL_sample_code_submission/`, which implements the logic of your\n",
    "algorithm. You can then test it in the exact same environment as the CodaLab\n",
    "environment using Docker. *WARNING*: You can choose to run local test out of the Docker\n",
    "image, but it's possible that certain Python packages you use are not installed\n",
    "in the Docker image used in the competition.\n",
    "\n",
    "If you are new to docker, install docker from https://docs.docker.com/get-started/.\n",
    "Then, at the shell, run:\n",
    "```\n",
    "cd path/to/AutoDL_starting_kit/\n",
    "docker run --memory=4g -it -u root -v $(pwd):/app/codalab evariste/autodl:dockerfile bash\n",
    "```\n",
    "You will then be able to run the ingestion program (to produce predictions) and\n",
    "the scoring program (to evaluate your predictions) on toy sample data. In AutoDL\n",
    "challenge, these two programs will run in parallel to give real-time feedback\n",
    "(with learning curves). So we provide a Python script to simulate this behavior:\n",
    "```\n",
    "python run_local_test.py\n",
    "```\n",
    "Then you can view the real-time feedback with a learning curve by opening the\n",
    "HTML page in `AutoDL_scoring_output/`.\n",
    "\n",
    "The full usage is\n",
    "```\n",
    "python run_local_test.py -dataset_dir='./AutoDL_sample_data/' -code_dir='./AutoDL_sample_code_submission/'\n",
    "```\n",
    "You can change the argument `dataset_dir` to other AutoDL datasets (e.g. those\n",
    "you downloaded from **Get Data** section of the challenge). On the other hand,\n",
    "you can also modify the directory containing your other sample code\n",
    "(`model.py`).\n",
    "\n",
    "WARNING: when you run local test in a Docker container, **make sure you distribute\n",
    "enough RAM** (at least 4GB). Otherwise, it's possible that certain task\n",
    "(especially when the dataset is large) will get 'Killed'. You can modify memory\n",
    "allocation of Docker in 'Preferences -> Advanced'.\n",
    "\n",
    "## How to prepare a ZIP file for submission\n",
    "Zip the contents of AutoDL_sample_code_submission (without the directory structure)\n",
    "```\n",
    "zip mysubmission.zip AutoDL_sample_code_submission/*\n",
    "```\n",
    "and use the \"Upload a Submission\" button for make a submission to CodaLab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import time \n",
    "#import webbrowser\n",
    "from multiprocessing import Process\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.flags.DEFINE_string('dataset_dir', './AutoDL_sample_data/',\n",
    "                       \"Directory containing the content (e.g. adult.data/ + \"\n",
    "                       \"adult.solution) of an AutoDL dataset. Specify this \"\n",
    "                       \"argument if you want to test on a different dataset.\")\n",
    "\n",
    "tf.flags.DEFINE_string('code_dir', './AutoDL_sample_code_submission',\n",
    "                       \"Directory containing a `model.py` file. Specify this \"\n",
    "                       \"argument if you want to test on a different algorithm.\")\n",
    "\n",
    "tf.flags.DEFINE_string('f', '', 'kernel') # <- used to fix a problem on jupyter (not needed on console)\n",
    "\n",
    "FLAGS = tf.flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_to_ingestion_program(starting_kit_dir):\n",
    "  return os.path.join(starting_kit_dir, 'AutoDL_ingestion_program', 'ingestion.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_to_scoring_program(starting_kit_dir):\n",
    "  return os.path.join(starting_kit_dir, 'AutoDL_scoring_program', 'score.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = FLAGS.dataset_dir\n",
    "code_dir = FLAGS.code_dir\n",
    "\n",
    "# Current directory containing this script\n",
    "#starting_kit_dir = os.path.dirname(os.path.realpath(__file__)) # <- use this on console\n",
    "starting_kit_dir = '' # <- use this on jupyter notebook\n",
    "\n",
    "path_ingestion = get_path_to_ingestion_program(starting_kit_dir)\n",
    "path_scoring = get_path_to_scoring_program(starting_kit_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run ingestion and scoring at the same time\n",
    "command_ingestion = 'python {} {} {}'.format(path_ingestion, dataset_dir, code_dir)\n",
    "command_scoring = 'python {} {}'.format(path_scoring, dataset_dir)\n",
    "def run_ingestion():\n",
    "  os.system(command_ingestion)\n",
    "def run_scoring():\n",
    "  os.system(command_scoring)\n",
    "ingestion_process = Process(name='ingestion', target=run_ingestion)\n",
    "scoring_process = Process(name='scoring', target=run_scoring)\n",
    "ingestion_process.start()\n",
    "scoring_process.start()\n",
    "\n",
    "detailed_results_page = os.path.join(starting_kit_dir,\n",
    "                                     'AutoDL_scoring_output',  \n",
    "                                     'detailed_results.html')\n",
    "#detailed_results_page = os.path.abspath(detailed_results_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait, generating the results...\n"
     ]
    }
   ],
   "source": [
    "print (\"wait, generating the results...\")\n",
    "while not(('score' in open(os.path.join(starting_kit_dir,'AutoDL_scoring_output','scores.txt')).read())):\n",
    "    time.sleep(1)\n",
    "display(HTML(detailed_results_page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
