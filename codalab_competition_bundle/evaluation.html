<h2>Quick start</h2>
<p>This is a challenge with code submission. We provide 3 baseline methods for test purposes (Note: to avoid that tests take too long, we set in model.py self.num_epochs_we_want_to_train = 1; you may change that):</p>
<p><strong><a href="../../my/datasets/download/593ef35d-c5c0-4759-a4d6-b8444a824ae3">Baseline 0</a>: Constant (zero) predictions</strong></p>
<p><strong><a href="../../my/datasets/download/14f52b54-4400-42ca-af6f-6fa0e0557ac6">Baseline 1</a>: Linear classifier</strong></p>
<p><strong><a href="../../my/datasets/download/48767c3d-d2b1-4dee-90ff-853762e8bac1">Baseline 2</a>: 3D Convolutional Neural Network</strong></p>
<p>To make a test submission, download one of the baseline methods, click on the blue button "<strong>Upload a Submission</strong>" in the upper right corner of the page and re-upload it. You must click first the orange tab <strong>"All datasets"</strong> if you want to make a submission simultaneously on all datasets and get ranked in the challenge. You may also submit on a single dataset at a time (for debug purposes). To check progress on your submissions go to the "<strong>My Submissions</strong>" tab. Your best submission is shown on the leaderboard visible under the "<strong>Results</strong>" tab.&nbsp;</p>
<h2>Complete starting kit</h2>
<p>The starting kit contains everything you need to create <strong>your own code submission</strong>&nbsp;(just by modifying the file model.py) and to test it on your local computer, with the same handling programs and Docker image as those of the Codalab platform (but the hardware environment is in general different). <strong><br /></strong></p>
<center>
<h3><span><a href="https://github.com/zhengying-liu/autodl_starting_kit_stable" target="_blank">Download the Starting Kit</a></span></h3>
<p style="text-align: left;">This includes a <strong>jupyter notebook <a href="https://nbviewer.jupyter.org/github/zhengying-liu/autodl_starting_kit_stable/blob/master/tutorial.ipynb" target="_blank">tutorial.ipynb</a></strong> with step-by-step instructions. The interface is simple and generic: you must supply a Python class <strong>model.py</strong> with:</p>
<ul style="text-align: left;">
<li>a constructor</li>
<li>a `train` method</li>
<li>a `test` method</li>
<li>a `done_training` attribute</li>
</ul>
<p style="text-align: left;">To make submissions,&nbsp;<strong>zip model.py (without the directory)</strong>, then use the "<strong>Upload a Submission</strong>" button. That's it!</p>
</center>
<h2>Computational limitations</h2>
<ul>
<li>A submission on one dataset is limited to a maximum of 20 minutes.</li>
<li>We currently limit participants to 5 hours of compute time per day (subject to change, depending on the number of participants).</li>
<li>Participants are limited to 5 submissions per day per dataset.</li>
</ul>
<p>Since for one dataset a submission may take up to 20 minutes and there are 5 datasets, if you do not stop your model early, you will only be able to make 3 full submissions (on all datasets) per day: 3 times x 5 datasets x (1/3 h)/dataset ~ 5h. However, you may manage your time in a more effective way by stopping your models early. This is done by setting the "done_training" attribute to "True" once you are done training, e.g. after a certain number of epochs.</p>
<h2>Larger practice datasets</h2>
<p style="text-align: left;">The starting kit contains sample data, but you may want to develop your code with larger practice datasets. We provide 8 public datasets for this purpose. You will have access to the data (training set and test set) AND the true labels for these datasets. Notice that the video datasets do not include a sound track.</p>
<table border="1" cellspacing="1" cellpadding="1" align="left">
<tbody>
<tr>
<td>&nbsp;#&nbsp;</td>
<td>&nbsp;Name</td>
<td>&nbsp;Type</td>
<td>&nbsp;Domain</td>
<td>&nbsp;Size</td>
<td>&nbsp;Source</td>
<td>
<p>&nbsp;Data (w/o test labels)</p>
</td>
<td>&nbsp;Test labels</td>
</tr>
<tr>
<td>&nbsp;1</td>
<td>&nbsp;Munster</td>
<td>&nbsp;Image</td>
<td>&nbsp;HWR</td>
<td>&nbsp;18 MB</td>
<td>&nbsp;<a href="http://yann.lecun.com/exdb/mnist/" target="_blank">MNIST</a></td>
<td>&nbsp;<a href="../../my/datasets/download/6662aa6e-75ab-439c-bf98-97dd11401053">munster.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/f3a61a40-b1f1-4ded-bc55-fb730a12f4c4">munster.solution</a></td>
</tr>
<tr>
<td>&nbsp;2</td>
<td>&nbsp;Chucky</td>
<td>&nbsp;Image</td>
<td>&nbsp;Objects</td>
<td>&nbsp;128 MB</td>
<td>&nbsp;<a href="https://www.cs.toronto.edu/~kriz/cifar.html">Cifar-100</a></td>
<td>&nbsp;<a href="../../my/datasets/download/d06aa5fc-1fb5-4283-8e05-abed4ccdd975">chucky.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/29932707-21cc-4670-a7db-cdc246a8ab71">chucky.solution</a></td>
</tr>
<tr>
<td>&nbsp;3</td>
<td>&nbsp;Pedro</td>
<td>&nbsp;Image</td>
<td>&nbsp;People</td>
<td>&nbsp;377 MB</td>
<td>&nbsp;<a href="https://github.com/xh-liu/HydraPlus-Net"><span style="font-size: 10pt; font-family: Arial; font-style: normal;" data-sheets-value="{&quot;1&quot;:2,&quot;2&quot;:&quot;PA-100K&quot;}" data-sheets-userformat="{&quot;2&quot;:513,&quot;3&quot;:{&quot;1&quot;:0},&quot;12&quot;:0}">PA-100K</span></a></td>
<td>&nbsp;<a href="../../my/datasets/download/61a074cd-e909-4d49-b313-7da0d4f7dc8b">pedro.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/852c1e68-5e91-477e-bef0-824b503814e8">pedro.solution</a></td>
</tr>
<tr>
<td>&nbsp;4</td>
<td>&nbsp;Decal</td>
<td>&nbsp;Image</td>
<td>&nbsp;Aerial</td>
<td>&nbsp;73 MB</td>
<td>&nbsp;<a href="http://www.escience.cn/people/gongcheng/NWPU-VHR-10.html">NWPU VHR-10</a></td>
<td>&nbsp;<a href="../../my/datasets/download/dfd93c39-e0d4-41b2-b332-4dd002676e05">decal.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/d72cba79-3051-4779-b624-e50335aad874">decal.solution</a></td>
</tr>
<tr>
<td>&nbsp;5</td>
<td>&nbsp;Hammer</td>
<td>&nbsp;Image</td>
<td>&nbsp;Medical</td>
<td>&nbsp;111 MB</td>
<td>&nbsp;<a href="https://www.nature.com/articles/sdata2018161">Ham10000</a></td>
<td>&nbsp;<a href="../../my/datasets/download/eb569948-72f0-4002-8e4d-479a27766cbf">hammer.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/c3729c98-4755-47a2-b764-a4159c5ca152">hammer.solution</a></td>
</tr>
<tr>
<td>&nbsp;6</td>
<td>&nbsp;Kraut</td>
<td>&nbsp;Video</td>
<td>&nbsp;Action</td>
<td>&nbsp;1.9 GB</td>
<td>&nbsp;<a href="https://www.nature.com/articles/sdata2018161">KTH</a></td>
<td>&nbsp;<a href="../../my/datasets/download/a1d9f706-cf8d-4a63-a544-552d6b85d6c4">kraut.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/47ff016d-cc66-47a9-945d-bc01fd9096c9">kraut.solution</a></td>
</tr>
<tr>
<td>&nbsp;7</td>
<td>&nbsp;Katze</td>
<td>&nbsp;Video</td>
<td>&nbsp;Action</td>
<td>&nbsp;1.9 GB</td>
<td>&nbsp;<a href="https://www.nature.com/articles/sdata2018161">KTH</a></td>
<td>&nbsp;<a href="../../my/datasets/download/611a42fa-da42-4a30-8c7a-69230d9eeb92">katze.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/a04de92e-b04b-49a6-96c2-5910c64f9b3c">katze.solution</a></td>
</tr>
<tr>
<td>&nbsp;8</td>
<td>&nbsp;Kreatur</td>
<td>&nbsp;Video</td>
<td>&nbsp;Action</td>
<td>&nbsp;469 MB</td>
<td>&nbsp;<a href="https://www.nature.com/articles/sdata2018161">KTH</a></td>
<td>&nbsp;<a href="../../my/datasets/download/08c2afcd-74b1-4c5e-8b93-9f6c9a96add2">kreatur.data</a></td>
<td>&nbsp;<a href="../../my/datasets/download/10e04890-f05a-4004-a499-1cc167769edd">kreatur.solution</a></td>
</tr>
</tbody>
</table>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp; </p>
<p>&nbsp;</p>
<table border="1" cellspacing="1" cellpadding="1" align="left">
<tbody>
<tr>
<td>
<p>&nbsp;#&nbsp;</p>
</td>
<td>&nbsp;Name</td>
<td>
<p>&nbsp;num_train</p>
</td>
<td>
<p>&nbsp;num_test</p>
</td>
<td>
<p>&nbsp;sequence_size</p>
</td>
<td>
<p>&nbsp;row_count</p>
</td>
<td>
<p>&nbsp;col_count</p>
</td>
<td>
<p>&nbsp;num_channels</p>
</td>
<td>&nbsp;output_dim&nbsp;</td>
<td>&nbsp;</td>
</tr>
<tr>
<td>&nbsp;1</td>
<td>&nbsp;Munster</td>
<td>&nbsp;60000</td>
<td>&nbsp;10000</td>
<td>&nbsp;1</td>
<td>&nbsp;28</td>
<td>&nbsp;28</td>
<td>&nbsp;1</td>
<td>&nbsp;10</td>
<td>&nbsp;</td>
</tr>
<tr>
<td>&nbsp;2</td>
<td>&nbsp;Chucky</td>
<td>&nbsp;48061</td>
<td>&nbsp;11939</td>
<td>&nbsp;1</td>
<td>&nbsp;32</td>
<td>&nbsp;32</td>
<td>&nbsp;3</td>
<td>&nbsp;100</td>
<td>&nbsp;</td>
</tr>
<tr>
<td>&nbsp;3</td>
<td>&nbsp;Pedro</td>
<td>&nbsp;80095</td>
<td>&nbsp;19905</td>
<td>&nbsp;1</td>
<td>&nbsp;-1</td>
<td>&nbsp;-1</td>
<td>&nbsp;3</td>
<td>&nbsp;26</td>
<td>&nbsp;</td>
</tr>
<tr>
<td>&nbsp;4</td>
<td>&nbsp;Decal</td>
<td>&nbsp;634</td>
<td>&nbsp;166</td>
<td>&nbsp;1</td>
<td>&nbsp;-1</td>
<td>&nbsp;-1</td>
<td>&nbsp;3</td>
<td>&nbsp;11</td>
<td>&nbsp;</td>
</tr>
<tr>
<td>&nbsp;5</td>
<td>&nbsp;Hammer</td>
<td>&nbsp;8050</td>
<td>&nbsp;1965</td>
<td>&nbsp;1</td>
<td>&nbsp;400</td>
<td>&nbsp;300</td>
<td>&nbsp;3</td>
<td>&nbsp;7</td>
<td>&nbsp;</td>
</tr>
<tr>
<td>&nbsp;6</td>
<td>&nbsp;Kraut</td>
<td>&nbsp;1528</td>
<td>&nbsp;863</td>
<td>&nbsp;181</td>
<td>&nbsp;120</td>
<td>&nbsp;160</td>
<td>&nbsp;1</td>
<td>&nbsp;4</td>
<td>&nbsp;</td>
</tr>
<tr>
<td>&nbsp;7</td>
<td>&nbsp;Katze</td>
<td>&nbsp;1528</td>
<td>&nbsp;863</td>
<td>&nbsp;181</td>
<td>&nbsp;120</td>
<td>&nbsp;160</td>
<td>&nbsp;1</td>
<td>&nbsp;6</td>
<td>&nbsp;</td>
</tr>
<tr>
<td>&nbsp;8</td>
<td>&nbsp;Kreatur</td>
<td>&nbsp;1528</td>
<td>&nbsp;863</td>
<td>&nbsp;181</td>
<td>&nbsp;60</td>
<td>&nbsp;80</td>
<td>&nbsp;3</td>
<td>&nbsp;4</td>
<td>&nbsp;</td>
</tr>
</tbody>
</table>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<ul>
<li>num_train/num_test: number of training/test examples</li>
</ul>
<ul>
<li>sequence_size/row_count/col_count/num_channels: shape parameters of the examples (in AutoCV challenge, every example is represented by a 4D tensor with axes t, x, y and c (t for time and c for channel)). A <em>row_count</em> or <em>col_count</em> of -1 means the value varies from one example to another.</li>
<li>output_dim: number of classes</li>
<li>has_locality_col (resp. has_locality_row): A flag indicating whether rows (resp. columns) in the tensor correspond to variables&nbsp;<span>interrelated</span> with some underlying topological structure ,reflected by the closeness of indices, like in images or videos.</li>
</ul>
<p>These data were re-formatted from original public datasets. If you use them, please make sure to acknowledge the original data donnors (see "Source" in the data table) and check the tems of use.</p>
<p><strong>To download all public datasets at once:</strong></p>
<pre>cd autodl_starting_kit_stable<br />python download_public_datasets.py</pre>
<h2>Format and use your own datasets</h2>
<p>Raw data are preserved, but formatted in a generic data format based on&nbsp;<a href="https://www.tensorflow.org/programmers_guide/datasets#consuming_tfrecord_data">TFRecords</a>, used by&nbsp;<a href="https://www.tensorflow.org/">TensorFlow</a>. However, this will not impose to participants to use deep learning algorithms nor even Tensorflow. If you want to practice designing algorithms with your own datasets, <a href="https://github.com/zhengying-liu/autodl-contrib/blob/master/README.md">follow these steps</a>.&nbsp;</p>
<h2>Competition protocol</h2>
<p>This challenge has<strong> two&nbsp;phases</strong>. This is the <strong>feed-back phase:</strong> when you submit your code, you get immediate feed-back on five development datasets. In the final test phase, you will be evaluated on five new datasets. Eligible participants to the final phase will be notified when and where to submit their code for a final blind test on these five new datasets. The ranking in the final phase will count towards determining the winners.</p>
<p>Code submitted is trained and tested automatically, without any human intervention. Code submitted on "All datasets" is run on all five development datasets in parallel on separate compute workers, each one with its own time budget.&nbsp;</p>
<p>The identities of the datasets used for testing on the platform are concealed.&nbsp;The data are provided in a&nbsp;<strong>raw form</strong>&nbsp;(no feature extraction) to encourage researchers to use Deep Learning methods performing automatic feature learning, although this is NOT a requirement. All problems are&nbsp;<strong>multi-label classification&nbsp;</strong>problems. The tasks are constrained by the&nbsp;<strong>time budget (20 minutes/dataset)</strong>.&nbsp;</p>
<p>Here is some pseudo-code of the evaluation protocol:</p>
<pre><code># For each dataset, our evaluation program calls the model constructor:
M =&nbsp;<strong>Model</strong>(metadata=dataset_metadata)
# Initialize
remaining_time budget = overall_time_budget
start_time = time()
# Ingestion program calls multiple times train and test:
repeat until M.done_training or remaining_time_budget &lt; 0
{
<strong>  M.train</strong> (training_data, remaining_time_budget)
  remaining_time_budget = start_time + overall_time_budget - time.time()
  results = <strong>M.test</strong>(test_data, remaining_time_budget)
  remaining_time_budget = start_time + overall_time_budget - time.time()<br />  # Results made available to scoring program (run in separate container)
  save(results)
}
</code></pre>
<p><span>It is the responsibility of the participants to make sure</span>&nbsp;that neither the "train" nor the "test" methods exceed the &ldquo;remaining_time_budget&rdquo;. The method &ldquo;train&rdquo; can choose to manage its time budget such that it trains in varying time increments.&nbsp;There is pressure that it does not use all "overall_time_budget" at the first iteration because we use the area under the learning curve as metric.</p>
<h2>Metrics</h2>
<p><span>The participants can train in batches of pre-defined duration to incrementally improve their performance</span>, until the time limit is attained. In this way we can plot learning curves:&nbsp;<strong>"performance" as a function of time</strong>. Each time the "train" method terminates, the "test" method is called and the results are saved, so the scoring program can use them, together with their timestamp.</p>
<p>We treat both multi-class and multi-label problems alike. Each label/class is considered a separate binary classification problem, and we compute the normalized AUC (or Gini coefficient)</p>
<p>&nbsp; &nbsp; 2 * AUC - 1</p>
<p>as score for each prediction, here AUC is the usual <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic">area under ROC curve</a> (ROC AUC).</p>
<p>For each dataset, we compute the&nbsp;<strong>Area under Learning Curve (ALC)</strong>. The learning curve is drawn as follows:</p>
<ul>
<li>at each timestamp t, we compute s(t), the normalized AUC (see above) of the <strong>most recent</strong> prediction. In this way, s(t) is a <strong>step function</strong> w.r.t time t;</li>
<li>in order to normalize time to the [0, 1] interval, we perform a time transformation by<br /><img style="vertical-align: middle;" src="http://drive.google.com/uc?export=view&amp;id=1_CLXY-QGqR1X7sWcA9OTjFUlu4R9zSil" alt="" width="164.7" height="53.7" /><br />where T is the time budget (of default value 1200 seconds = 20 minutes) and t0 is a reference time amount (of default value 60 seconds).</li>
<li>then compute the area under learning curve using the formula<br /><img style="vertical-align: middle;" src="http://drive.google.com/uc?export=view&amp;id=19iHGsesbF9YnvwoYSQURa7_DegmcoQzp" alt="" width="285" height="165" /><br />we see that s(t) is weighted by 1/(t + t0)), giving a stronger importance to predictions made at the beginning of th learning curve.</li>
</ul>
<p>After we compute the ALC for all 5 datasets, the&nbsp;<strong>overall ranking</strong>&nbsp;is used as the final score for evaluation and will be used in the learderboard. It is computed by averaging the ranks (among all participants) of ALC obtained on the 5 datasets.</p>
<p>Examples of learning curves:</p>
<p><img style="vertical-align: middle;" src="http://drive.google.com/uc?export=view&amp;id=1RBfs5yYrKHmQa2iBKN9COkg5iov8Znxl" alt="" width="500" height="505" /></p>
<p><img src="http://drive.google.com/uc?export=view&amp;id=17rsJ68BimMAlKGZkcstVW277iMxO4qEc" alt="" width="500" height="505" /></p>
